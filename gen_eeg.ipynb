{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ede42c",
   "metadata": {},
   "source": [
    "EEG generation with VAE - taken from https://github.com/arkanivasarkar/EEG-Data-Augmentation-using-Variational-Autoencoder/blob/main/VAE%20model%20for%20EEG%20Data%20Augmentation.ipynb, translated from tensorflow to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9411403",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bci_iv_2a_data/A01/train/0/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m direc = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbci_iv_2a_data/A01/train/0/\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# data directory\u001b[39;00m\n\u001b[32m      6\u001b[39m train_dataset = []\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m files = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[32m      9\u001b[39m     filename = glob.glob(direc + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + name)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'bci_iv_2a_data/A01/train/0/'"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Output directory MUST match your loader\n",
    "# ----------------------------\n",
    "OUT_DIR = r\"bci_iv_2a_data/A01/train/0\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Download / load settings\n",
    "# ----------------------------\n",
    "SUBJECTS = [1]          # start with one subject; add more later (1..109)\n",
    "RUNS = [6, 10]          # motor imagery runs in EEGMMIDB\n",
    "SFREQ_TARGET = 250      # so 4 seconds -> 1000 samples\n",
    "TMIN, TMAX = 0.0, 4.0   # epoch length 4s\n",
    "\n",
    "# A consistent 22-channel subset (falls back if some missing)\n",
    "PICK_22 = [\n",
    "    \"Fz\",\"FC3\",\"FC1\",\"FCz\",\"FC2\",\"FC4\",\n",
    "    \"C5\",\"C3\",\"C1\",\"Cz\",\"C2\",\"C4\",\"C6\",\n",
    "    \"CP3\",\"CP1\",\"CPz\",\"CP2\",\"CP4\",\n",
    "    \"Pz\",\"POz\",\"Oz\",\"P3\"\n",
    "]\n",
    "\n",
    "def pick_22_channels(raw_or_epochs, desired):\n",
    "    obj = raw_or_epochs.copy().pick_types(eeg=True, meg=False, eog=False, ecg=False, stim=False, emg=False, exclude=[])\n",
    "    chs = obj.ch_names\n",
    "    chosen = [ch for ch in desired if ch in chs]\n",
    "    if len(chosen) >= 22:\n",
    "        return chosen[:22]\n",
    "    return chs[:22]\n",
    "\n",
    "file_count = 0\n",
    "\n",
    "for subj in SUBJECTS:\n",
    "    edf_files = eegbci.load_data(subj, RUNS)\n",
    "    raws = [mne.io.read_raw_edf(f, preload=True, verbose=False) for f in edf_files]\n",
    "    raw = mne.concatenate_raws(raws)\n",
    "\n",
    "    raw.set_montage(\"standard_1020\", on_missing=\"ignore\")\n",
    "\n",
    "    # Basic MI preprocessing\n",
    "    raw.filter(8.0, 30.0, fir_design=\"firwin\")\n",
    "    raw.notch_filter([50, 100])\n",
    "    raw.set_eeg_reference(\"average\", projection=False)\n",
    "\n",
    "    # Force 1000 timesteps per epoch (4s at 250 Hz)\n",
    "    raw.resample(SFREQ_TARGET)\n",
    "\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Keep imagery events. EEGMMIDB uses T1/T2 for imagery and T0 for rest.\n",
    "    keep = {k: v for k, v in event_id.items() if k in (\"T1\", \"T2\")}\n",
    "    if not keep:\n",
    "        raise RuntimeError(f\"No T1/T2 events found. event_id={event_id}\")\n",
    "\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events, event_id=keep,\n",
    "        tmin=TMIN, tmax=TMAX,\n",
    "        baseline=None, preload=True, verbose=False\n",
    "    )\n",
    "\n",
    "    chosen_22 = pick_22_channels(epochs, PICK_22)\n",
    "    epochs = epochs.copy().pick_channels(chosen_22)\n",
    "\n",
    "    X = epochs.get_data()  # (n_epochs, 22, 1000)\n",
    "    if X.shape[1] != 22 or X.shape[2] != 1000:\n",
    "        raise RuntimeError(f\"Got shape {X.shape}, expected (n, 22, 1000). Check picks or resampling/window.\")\n",
    "\n",
    "    # Write CSVs in EXACT format your loader expects:\n",
    "    # 22 rows, 1001 cols: [channel_name | 1000 samples]\n",
    "    for i in range(X.shape[0]):\n",
    "        arr = X[i]  # (22,1000)\n",
    "        df = pd.DataFrame(arr)\n",
    "        df.insert(0, 0, chosen_22)  # first column index 0 contains strings (channel names)\n",
    "        out_path = os.path.join(OUT_DIR, f\"sub{subj:03d}_epoch{i:05d}.csv\")\n",
    "        df.to_csv(out_path, header=False, index=False)\n",
    "        file_count += 1\n",
    "\n",
    "print(f\"Wrote {file_count} CSV epoch files to {OUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
