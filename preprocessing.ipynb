{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa3bfb0",
   "metadata": {},
   "source": [
    "## Convert raw GDF files into individual per-trial CSV files\n",
    "1. Read each subject’s TRAINING file (A01T.gdf, etc.)\n",
    "2. Extract events from the file\n",
    "3. For every cue event (769–772):\n",
    "- That timestamp = cue onset\n",
    "- Extract 4 seconds of data starting at cue onset\n",
    "- That equals 1000 samples\n",
    "4. Keep only channels 0–21 (first 22 channels)\n",
    "- Drop last 3 EOG channels.\n",
    "5. Each extracted segment becomes one trial: Shape = (22, 1000)\n",
    "6. Convert class labels:\n",
    "769 → class 0\n",
    "770 → class 1\n",
    "771 → class 2\n",
    "772 → class 3\n",
    "7. Split trials into:\n",
    "- 80% training\n",
    "- 20% test\n",
    "(stratified so class balance stays equal)\n",
    "8. Save each trial as a CSV:\n",
    "- 22 rows\n",
    "- 1000 columns\n",
    "- First column = channel name (optional but your classifier loader expects it)\n",
    "- Remaining columns = numeric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PSEUDOCODE (Python-style) for the full pipeline:\n",
    "1) Preprocess raw GDF into per-trial CSVs in Original/ directory\n",
    "2) Train a per-(subject,class) VAE generator and write Generated/ directory\n",
    "3) Train/evaluate classifier twice (original-trained vs generated-trained)\n",
    "\n",
    "This is NOT runnable code. It is structured pseudocode to show exactly what to do.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIG / CONSTANTS\n",
    "# ---------------------------\n",
    "\n",
    "SUBJECTS = [\"A01\", \"A02\", \"A03\", \"A04\", \"A05\", \"A06\", \"A07\", \"A08\", \"A09\"]\n",
    "\n",
    "# Event codes (from dataset description)\n",
    "CUE_TO_CLASS = {\n",
    "    769: 0,  # left hand\n",
    "    770: 1,  # right hand\n",
    "    771: 2,  # feet\n",
    "    772: 3,  # tongue\n",
    "}\n",
    "\n",
    "SFREQ = 250                     # Hz\n",
    "EPOCH_SECONDS = 4               # use 4s of data after cue onset (2s->6s)\n",
    "EPOCH_SAMPLES = SFREQ * EPOCH_SECONDS  # 1000\n",
    "\n",
    "N_EEG_CHANNELS = 22             # drop the 3 EOG channels\n",
    "\n",
    "TRAIN_SPLIT = 0.80              # 80/20 split\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "# Output directory\n",
    "OUT_ROOT = Path(\"bci_iv_2a_data\")\n",
    "ORIGINAL_ROOT = OUT_ROOT / \"Original\"\n",
    "GENERATED_ROOT = OUT_ROOT / \"Generated\"\n",
    "# ============================================================\n",
    "# PART 1: PREPROCESSING (GDF -> Original/<subject>/{train,test}/{0..3}/*.csv)\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_all_subjects(gdf_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    For each subject:\n",
    "      - Load subject's training GDF (e.g., A01T.gdf)\n",
    "      - Extract cue events (769..772)\n",
    "      - Epoch 4s (1000 samples) from cue onset\n",
    "      - Keep 22 EEG channels\n",
    "      - Map cue code -> class index 0..3\n",
    "      - Split epochs into train/test\n",
    "      - Save each epoch as CSV into the required folder structure\n",
    "    \"\"\"\n",
    "    for subj in SUBJECTS:\n",
    "        gdf_path = gdf_dir / f\"{subj}T.gdf\"\n",
    "        raw = read_gdf(gdf_path)  # returns continuous multichannel signal + metadata\n",
    "\n",
    "        events = extract_events(raw)  # list of (sample_index, event_code)\n",
    "        cue_events = filter_events(events, allowed_codes=set(CUE_TO_CLASS.keys()))\n",
    "\n",
    "        trials, labels = [], []\n",
    "\n",
    "        for (sample_index, event_code) in cue_events:\n",
    "            # 1) Compute segment boundaries\n",
    "            start = sample_index\n",
    "            end = sample_index + EPOCH_SAMPLES\n",
    "\n",
    "            # 2) Extract signal segment (channels x time)\n",
    "            segment = raw_signal_slice(raw, start=start, end=end)  # shape: (all_channels, EPOCH_SAMPLES)\n",
    "\n",
    "            # 3) Keep EEG only (drop EOG)\n",
    "            eeg_segment = segment[:N_EEG_CHANNELS, :]  # shape: (22, 1000)\n",
    "\n",
    "            # 4) Store trial and mapped label\n",
    "            cls = CUE_TO_CLASS[event_code]\n",
    "            trials.append(eeg_segment)\n",
    "            labels.append(cls)\n",
    "\n",
    "        # 5) Split into train/test in a stratified way (keep class balance)\n",
    "        X_train, X_test, y_train, y_test = stratified_split(\n",
    "            X=trials, y=labels, train_ratio=TRAIN_SPLIT, seed=RANDOM_SEED\n",
    "        )\n",
    "\n",
    "        # 6) Create folders and write CSV files\n",
    "        create_original_folders(subject=subj)\n",
    "\n",
    "        write_trials_to_csv(\n",
    "            X_train, y_train,\n",
    "            out_dir=ORIGINAL_ROOT / subj / \"train\",\n",
    "            include_channel_name_column=True,   # matches repo expectation for Original\n",
    "        )\n",
    "\n",
    "        write_trials_to_csv(\n",
    "            X_test, y_test,\n",
    "            out_dir=ORIGINAL_ROOT / subj / \"test\",\n",
    "            include_channel_name_column=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def create_original_folders(subject: str) -> None:\n",
    "    \"\"\"\n",
    "    Create:\n",
    "      Original/<subject>/{train,test}/{0,1,2,3}/\n",
    "    \"\"\"\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        for cls in [0, 1, 2, 3]:\n",
    "            (ORIGINAL_ROOT / subject / split / str(cls)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def write_trials_to_csv(X, y, out_dir: Path, include_channel_name_column: bool) -> None:\n",
    "    \"\"\"\n",
    "    Save each trial as CSV into out_dir/<class>/trial_XXXXX.csv\n",
    "\n",
    "    Each trial is a matrix: 22 x 1000\n",
    "    If include_channel_name_column is True:\n",
    "      - first column is a channel name string (so the classifier loader can drop it)\n",
    "      - remaining columns are numeric\n",
    "    If False:\n",
    "      - numeric only (for Generated data compatibility)\n",
    "    \"\"\"\n",
    "    counters = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "\n",
    "    for trial, cls in zip(X, y):\n",
    "        idx = counters[cls]\n",
    "        counters[cls] += 1\n",
    "\n",
    "        cls_dir = out_dir / str(cls)\n",
    "        cls_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        filename = cls_dir / f\"trial_{idx:05d}.csv\"\n",
    "\n",
    "        # Pseudocode for writing:\n",
    "        # if include_channel_name_column:\n",
    "        #   csv rows: [\"C3\", v1, v2, ..., v1000]\n",
    "        # else:\n",
    "        #   csv rows: [v1, v2, ..., v1000]\n",
    "        write_csv_matrix(filename, trial, include_channel_name_column=include_channel_name_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48d801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
